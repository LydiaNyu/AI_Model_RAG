[
    {
        "question_id": 1,
        "question": "How much faster did the treatment group complete the task in the Peng2023 study?",
        "timestamp": "2026-02-15T21:43:28.661457",
        "answer": "In the Peng2023 study, the treatment group, which had access to GitHub Copilot, completed the task 55.8% faster than the control group. The average completion time for the treatment group was 71.17 minutes, compared to 160.89 minutes for the control group. This performance difference is statistically significant, with a p-value of 0.0017 and a 95% confidence interval for the improvement ranging from 21% to 89% (Peng2023).",
        "retrieved_source_ids": [
            "Choudhuri2024",
            "Peng2023"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 2,
                "content_snippet": "did not have access to GitHub Copilot but was otherwise unconstrained, i.e., they were free to\nuse internet search and Stack OverÔ¨Çow to complete the task.\nThe performance difference between treated and control groups are statistically and practi-\ncally signiÔ¨Åcant: the treated group completed the tas..."
            },
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 5,
                "content_snippet": "Most of the participants are in the age group of 25-34 and come from India and Pakistan.\nThis group of participants is also characterized by relatively lower income (median yearly in-\ncome between $10,000-$19,000) compared to US standards but high education level (the ma-\njority have a 4-year degree..."
            },
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 17,
                "content_snippet": "Figure 6: Time to task completion\nNote: Distribution of time to task completion between treated (blue) and control (orange) groups\n17"
            },
            {
                "source_id": "Choudhuri2024",
                "year": 2024,
                "page": 5,
                "content_snippet": "Senior 4 5 9\nEnrolled in SE Courses 3 4 7\nEnrolled in SE Courses + Worked on SE\nProjects\n8 7 15\nTotal 11 11 22\nStudy Protocol: All studies were in lab sessions at the University\nlab with up to 3 participants at a time, following the university IRB\nprotocol. The study proceeded as follows: the partic..."
            }
        ],
        "latency_seconds": 3.22
    },
    {
        "question_id": 2,
        "question": "What did Weber2024 find regarding the impact of AI on task completion time?",
        "timestamp": "2026-02-15T21:43:32.735810",
        "answer": "Weber2024 found that the use of AI in programming significantly reduced task completion time. Specifically, there was a reduction in task completion time by more than half when using AI, although participants estimated the increase in speed to be about 35% (Weber2024 - Page 5). Additionally, the study noted that participants using AI assistants displayed significantly different task completion times compared to the control condition, with statistical significance reported (ùëù = 0.028 for auto-complete and ùëù = 0.025 for conversational AI, using a pairwise Wilcoxon test) (Weber2024 - Page 14). However, it was also observed that some participants did not thoroughly verify the AI-generated code, which could lead to erroneous solutions and time-consuming debugging (Weber2024 - Page 16).",
        "retrieved_source_ids": [
            "Choudhuri2024",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 5,
                "content_snippet": "reduction in task completion time by more than half. Participants noted the increase in speed but\nestimated it to be only about 35%. Furthermore, while the control group took a bit longer, the\ntask success rate was not significantly different. In contrast, Vaithilingam et al . [60] found that\npartic..."
            },
            {
                "source_id": "Choudhuri2024",
                "year": 2024,
                "page": 5,
                "content_snippet": "tasks: Task 1 was allotted 20 minutes, and tasks 2 and 3 had 10\nminutes each. This change facilitated on-time conclusions and time\nfor briefing and questionnaires (40 minutes).\nOur sandboxing also revealed difficulties with the AAR/AI pro-\ncess: participants found it burdensome, resulting in sparse..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 16,
                "content_snippet": "times as many requirements per minute as their peers.\nWhile we set the task to take approximately 15 minutes, not all participants took this much\ntime. While the majority spent about this much or slightly longer on the tasks, two participants\ntook less than half the time. P19 completed the task in t..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 14,
                "content_snippet": "Figure 7 with the AI assistants displaying significantly different task completion times than the\ncontrol condition (auto-complete: ùëù = 0.028, conversational: ùëù = 0.025, pairwise Wilcoxon test,\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. EICS, Article 256. Publication date: June 2024."
            }
        ],
        "latency_seconds": 4.07
    },
    {
        "question_id": 3,
        "question": "Does GitHub Copilot significantly improve task success rates according to Vaithilingam2022?",
        "timestamp": "2026-02-15T21:43:35.441651",
        "answer": "According to Vaithilingam et al. (2022), GitHub Copilot did not cause a significant improvement in task success rates. The study found that participants failed to complete tasks more often using Copilot compared to just using IntelliSense, and it did not have a significant impact on task completion time (Yetistiren2023). Additionally, it was noted that an overreliance on the AI led to erroneous solutions being accepted without thorough review, resulting in time-consuming debugging (Weber2024). Therefore, the evidence suggests that GitHub Copilot does not significantly improve task success rates according to Vaithilingam2022.",
        "retrieved_source_ids": [
            "Yetistiren2023",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 5,
                "content_snippet": "reduction in task completion time by more than half. Participants noted the increase in speed but\nestimated it to be only about 35%. Furthermore, while the control group took a bit longer, the\ntask success rate was not significantly different. In contrast, Vaithilingam et al . [60] found that\npartic..."
            },
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 41,
                "content_snippet": "was implemented by Pearce et al. (2021). They evaluated the vulnerabilities in the\ncode generated by Copilot. It was determined that 40% of generated programs were\nvulnerable. These results differed from our Code Security results; we believe that the\ncharacteristics of our dataset caused the differe..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 5,
                "content_snippet": "significantly better scores, there was a shift in tasks, with more time being spent on debugging.\nWith GitHub now offering both types of systems, GitHub Copilot and GitHub Copilot Chat,\nthey are in a position to provide additional insights from their customer data and evaluations.\nAccording to that,..."
            },
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 31,
                "content_snippet": "while GitHub Copilot v1.7.4421 had passed suggestions for 28.7% the unit tests and\naverage correctness for 53.6% of all problems. This data indicates that there is a notable\nimprovement of 62% in GitHub Copilot‚Äôs performance in terms of passed suggestions\nfor unit tests and there is an improvement o..."
            }
        ],
        "latency_seconds": 2.71
    },
    {
        "question_id": 4,
        "question": "What is the 'bimodal' interaction pattern (Acceleration vs Exploration) described in Barke2023?",
        "timestamp": "2026-02-15T21:43:41.037249",
        "answer": "The 'bimodal' interaction pattern described in Barke2023 refers to two distinct modes of interaction that programmers have with code-generating models like Copilot: Acceleration and Exploration.\n\n1. **Acceleration Mode**: In this mode, programmers are described as being \"in the zone\" and actively driving the development process. They use Copilot as an \"intelligent autocomplete\" to complete their thought process quickly without losing focus. This mode is characterized by programmers accepting Copilot's suggestions with minimal deliberation, as they already have a clear idea of the code they want to write and use Copilot to type it out faster than they could themselves (Barke2023, Page 7).\n\n2. **Exploration Mode**: This mode involves a more deliberate and slower interaction, often referred to as the \"slow System 2\" mode. Programmers spend more time in this mode as it involves exploring different possibilities and solutions. The study found that participants spent more than twice the amount of time in exploration mode compared to acceleration mode (Barke2023, Page 16). In exploration mode, participants are more likely to prompt Copilot with comments and use the multi-suggestion pane to explore a rich body of suggestions (Barke2023, Page 18).\n\nThe study also notes that the time spent in these modes can vary based on factors such as language expertise, prior Copilot usage, the nature of the task, and the programming language. For instance, professional participants with more language expertise tend to spend more time in acceleration mode, as they are more likely to know how to solve the task in the given language (Barke2023, Page 16).",
        "retrieved_source_ids": [
            "Barke2023"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Barke2023",
                "year": 2023,
                "page": 5,
                "content_snippet": "2016]. We describe our process below.\nWe began our study with the blank slate question: ‚ÄúHow do programmers interact with Copilot?‚Äù\nOur bimodal theory of acceleration and exploration was not yet formed. During each session, we\ntook notes to guide our semi-structured interview. After each session, we..."
            },
            {
                "source_id": "Barke2023",
                "year": 2023,
                "page": 18,
                "content_snippet": "1:18 Shraddha Barke, Michael B. James, and Nadia Polikarpova\nAcceleration Exploration\n0\n20\n40\n60\n80\n100% Time spent in each validation strategy\nValidation strategies in the two interaction modes\nExamination\nExecution\nDocumentation\n(a) Aggregate time, split by interaction mode.\nChat Server\n(n=5)\nChat..."
            },
            {
                "source_id": "Barke2023",
                "year": 2023,
                "page": 7,
                "content_snippet": "bimodal theory. Each named paragraph heading is an aspect of that hypothesis.\n4.1 Acceleration\nAcceleration is characterized by the programmer being ‚Äúin the zone‚Äù and actively ‚Äúdriving‚Äù the de-\nvelopment, while occasionally relying on Copilot to complete their thought process. A programmer\nwill ofte..."
            },
            {
                "source_id": "Barke2023",
                "year": 2023,
                "page": 16,
                "content_snippet": "5.1.1 Time spent in interaction modes. The total amount of study time spent by all participants\ninteracting with Copilot in exploration mode (248.6 minutes) is more than twice that in acceleration\nmode (104.7 minutes). This is not surprising, since exploration is the ‚Äúslow System 2‚Äù mode, where\neach..."
            }
        ],
        "latency_seconds": 5.6
    },
    {
        "question_id": 5,
        "question": "According to Liang2024, what are the top reasons developers choose to use AI tools?",
        "timestamp": "2026-02-15T21:43:43.965064",
        "answer": "According to Liang2024, the top reasons developers choose to use AI tools include the ability to reduce key-strokes, finish programming tasks quickly, and recall syntax. These motivations are primarily related to increasing efficiency and productivity in coding tasks. Developers are less motivated to use these tools for brainstorming potential solutions (Liang2024 - Page 1). Additionally, developers use AI tools for tasks such as autocompleting code, finishing programming tasks faster, and not needing to go online to find code snippets. These motivations are more frequently associated with acceleration mode, such as handling repetitive code and simple logic, rather than exploration mode, like discovering new ways to write a solution or finding edge cases (Liang2024 - Page 10).",
        "retrieved_source_ids": [
            "Liang2024",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Liang2024",
                "year": 2024,
                "page": 1,
                "content_snippet": "a diverse set of 410 developers. Through a mix of qualitative and\nquantitative analyses, we found that developers are most motivated\nto use AI programming assistants because they help developers\nreduce key-strokes, finish programming tasks quickly, and recall\nsyntax, but resonate less with using the..."
            },
            {
                "source_id": "Liang2024",
                "year": 2024,
                "page": 10,
                "content_snippet": "when developers use AI programming assistants (e.g., repetitive\ncode, code with simple logic , autocomplete, recalling versus\nproof-of-concepts), why developers use these tools (e.g., autocom-\npleting (M1), finishing programming tasks faster (M2), not needing\nto go online to find code snippets (M3)..."
            },
            {
                "source_id": "Liang2024",
                "year": 2024,
                "page": 2,
                "content_snippet": "ICSE 2024, April 14‚Äì20, 2024, Lisbon, Portugal Liang et al.\nincreasing the adoption of these tools and improving the produc-\ntivity of developers. Usability is an important factor to study in AI\nprogramming assistants, since modeling improvements may not\nnecessarily address the needs of developers,..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 23,
                "content_snippet": "advisable not to focus on just one form of presentation and interaction for LLMs in software\ndevelopment, but rather offer developers the flexibility to choose their tools according to their\nneeds from situation to situation. However, this also means that a transition between different\ninteraction f..."
            }
        ],
        "latency_seconds": 2.93
    },
    {
        "question_id": 6,
        "question": "What percentage of code generated by Copilot contained vulnerabilities in the Pearce2022 study?",
        "timestamp": "2026-02-15T21:43:46.787592",
        "answer": "In the Pearce2022 study, it was found that approximately 40% of the code generated by GitHub Copilot contained vulnerabilities. Specifically, across all scenarios and languages, 39.33% of the top options and 40.73% of the total options were identified as vulnerable (Pearce2022, Page 13). Additionally, in a detailed analysis of 54 scenarios across 18 different CWEs, 44.00% of the 1084 valid programs generated were determined to contain a CWE (Pearce2022, Page 5). This consistent finding across different analyses within the study highlights a significant concern regarding the security of code generated by Copilot.",
        "retrieved_source_ids": [
            "Yetistiren2023",
            "Pearce2022"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 41,
                "content_snippet": "was implemented by Pearce et al. (2021). They evaluated the vulnerabilities in the\ncode generated by Copilot. It was determined that 40% of generated programs were\nvulnerable. These results differed from our Code Security results; we believe that the\ncharacteristics of our dataset caused the differe..."
            },
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 13,
                "content_snippet": "VI. D ISCUSSION\nOverall, Copilot‚Äôs response to our scenarios is mixed from a\nsecurity standpoint, given the large number of generated vul-\nnerabilities (across all axes and languages, 39.33 % of the top\nand 40.73 % of the total options were vulnerable). The security\nof the top options are particular..."
            },
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 5,
                "content_snippet": "scoring option was non-vulnerable (safe)). Copilot Score\nSpreads provides box-plots of the scores for the Copilot-\ngenerated options after checking whether or not each option\nmakes a non-vulnerable (N-V) or vulnerable (V) program.\nIn total, we designed 54 scenarios across 18 different\nCWEs. From the..."
            },
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 1,
                "content_snippet": "often contains bugs‚Äîand so, given the vast quantity of unvetted\ncode that Copilot has processed, it is certain that the language\nmodel will have learned from exploitable, buggy code. This raises\nconcerns on the security of Copilot‚Äôs code contributions. In this\nwork, we systematically investigate the..."
            }
        ],
        "latency_seconds": 2.82
    },
    {
        "question_id": 7,
        "question": "Does Perry2023 find that users write more secure or less secure code with AI assistants?",
        "timestamp": "2026-02-15T21:43:49.121458",
        "answer": "Perry2023 finds that users write less secure code when using AI assistants. The study indicates that participants with access to an AI assistant produced significantly less secure code compared to those without access to such tools (Perry2023 - Page 1). Additionally, the research highlights that users with AI assistance were more likely to believe they wrote secure code, which suggests a potential overconfidence in the security of their code when using these tools (Perry2023 - Page 1). Furthermore, the study notes that participants who used AI assistants were more likely to trust the AI to produce secure code, even when their solutions were insecure (Perry2023 - Page 9).",
        "retrieved_source_ids": [
            "Perry2023"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 1,
                "content_snippet": "Do Users Write More Insecure Code with AI Assistants?\nNeil Perry‚àó\nStanford University\nMegha Srivastava‚àó\nStanford University\nDeepak Kumar\nStanford University / UC\nSan Diego\nDan Boneh\nStanford University\nABSTRACT\nAI code assistants have emerged as powerful tools that can aid in\nthe software developmen..."
            },
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 1,
                "content_snippet": "they wrote secure code, suggesting that such tools may lead users\nto be overconfident about security flaws in their code. To better\ninform the design of future AI-based code assistants, we release our\nuser-study apparatus and anonymized data to researchers seeking\nto build on our work at this link...."
            },
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 1,
                "content_snippet": "typically produced less secure code (Section 4). To make matters\nworse, participants that were provided access to an AI assistant\nwere more likely to believe that they wrote secure code than those\nwithout access to the AI assistant, highlighting the potential pitfalls\nof deploying such tools without..."
            },
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 9,
                "content_snippet": "Do Users Write More Insecure Code with AI Assistants? CCS ‚Äô23, November 26‚Äì30, 2023, Copenhagen, Denmark.\n‚ÄúI think I solved this task correctly‚Äù\n‚ÄúI think I solved this task securely‚Äù\n‚ÄúI trusted the AI to produce secure code‚Äù\nStrongly DisagreeDisagree Neither Agree Strongly Agree\nFigure 2: Participan..."
            }
        ],
        "latency_seconds": 2.33
    },
    {
        "question_id": 8,
        "question": "According to Kabir2024, what percentage of ChatGPT answers contained incorrect information?",
        "timestamp": "2026-02-15T21:43:51.505728",
        "answer": "According to Kabir2024, more than half of the ChatGPT answers, specifically 52%, contained incorrect information (Kabir2024).",
        "retrieved_source_ids": [
            "Yetistiren2023",
            "Kabir2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Kabir2024",
                "year": 2024,
                "page": 7,
                "content_snippet": "Our results show that, among the 517 ChatGPT answers we labeled,\n52% of them contain incorrect information, 78% are inconsis tent\nfrom human answers, 35% lack comprehensiveness, and 77% con -\ntain redundant, irrelevant, or unnecessary information. M oreover,\non average, ChatGPT answers and human ans..."
            },
            {
                "source_id": "Kabir2024",
                "year": 2024,
                "page": 7,
                "content_snippet": "in ChatGPT Answers\nOur thematic analysis reveals four types of incorrectness in Chat-\nGPT answers‚Äî Conceptual (54%), Factual (36%), Code (28%) and Ter-\nminology (12%) errors. Note that these errors are not mutually ex-\nclusive. Some answers have more than one of these errors. Factual\nerrors occur wh..."
            },
            {
                "source_id": "Kabir2024",
                "year": 2024,
                "page": 10,
                "content_snippet": "Additionally, 5 participants found unexpected or impossible errors\nas a helpful factor in identifying the machine-generated an swers.\nApart from these, tricks and insights that only experienced people\ncan provide (5 out of 12 participants), and high entropy gene ra-\ntion (1 out of 12 participants) w..."
            },
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 13,
                "content_snippet": "code was generated with a correctness score in the interval of75% ‚â• CCS i > 50%,\n37.9% of the time. The next interval contained the partially correct code generations\nwith a score of21.2%, belonging to the interval of50% ‚â• CCS i > 25%. For the last\ninterval of25% ‚â• CCS i > 0%, the score was25.7%. Ad..."
            }
        ],
        "latency_seconds": 2.38
    },
    {
        "question_id": 9,
        "question": "Did Yetistiren2023 find that AI-generated code is more maintainable than human code?",
        "timestamp": "2026-02-15T21:43:53.174100",
        "answer": "I cannot find evidence in the provided corpus to answer whether Yetistiren2023 found that AI-generated code is more maintainable than human code. The context mentions that Yetistiren2023 evaluated code maintainability among other metrics, but it does not provide specific findings or comparisons between AI-generated and human-written code regarding maintainability (Yetistiren2023, Source 2; Source 3).",
        "retrieved_source_ids": [
            "Yetistiren2023",
            "Vaithilingam2022"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 42,
                "content_snippet": "42 Burak Yeti≈ütiren et al.\nFor code understandability, they determined that there was no statistical significance\nbetween the programming languages.\nMastropaolo et al. (2023) presented an empirical study that focuses on the effect of\nsemantic-preserving changes in the natural language on the generat..."
            },
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 1,
                "content_snippet": "Noname manuscript No.\n(will be inserted by the editor)\nEvaluating the Code Quality of AI-Assisted Code\nGeneration Tools: An Empirical Study on GitHub Copilot,\nAmazon CodeWhisperer, and ChatGPT\nBurak Yeti≈ütiren¬∑ I≈üƒ±k √ñzsoy¬∑ Miray\nAyerdem ¬∑ Eray T√ºz√ºn\nthe date of receipt and acceptance should be inser..."
            },
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 41,
                "content_snippet": "models that OpenAI previously developed for natural language generation. The public\ncode available on GitHub was used here while fine-tuning the model to implement the\ncode recognition and generation capabilities. This model can recognize other elements\nsuch as function signatures, code comments, et..."
            },
            {
                "source_id": "Vaithilingam2022",
                "year": 2022,
                "page": 2,
                "content_snippet": "also suffer from inherent uncertainty and imperfection. They may\ninevitably generate code with errors or even code that wildly differs\nfrom users‚Äô expectations. However, unlike other domains, code\ngeneration demands a much higher level of correctness: code either\ncompiles or not, and it is either co..."
            }
        ],
        "latency_seconds": 1.67
    },
    {
        "question_id": 10,
        "question": "What specific security vulnerabilities (CWEs) were most common in Pearce2022's analysis?",
        "timestamp": "2026-02-15T21:43:57.632934",
        "answer": "In Pearce2022's analysis, several specific security vulnerabilities, known as Common Weakness Enumerations (CWEs), were identified as common. The study found that out of 198 programs generated by GitHub Copilot, 56 (28.28%) were vulnerable. Among the scenarios designed for hardware CWEs, 7 out of 18 (38.89%) had vulnerable top-scoring options (Pearce2022 - Page 11). \n\nThe analysis specifically mentions CWE-1234, which involves hardware internal or debug modes allowing override of locks, as a notable vulnerability (Pearce2022 - Page 11). Additionally, the study discusses the exclusion of certain CWEs from analysis due to their architectural nature or the need for context beyond the source code, such as CWE-352 (Cross-Site Request Forgery), CWE-862 (Missing Authorization), and CWE-276 (Incorrect Default Permissions) (Pearce2022 - Page 15). These exclusions highlight the complexity and context-dependence of certain vulnerabilities that were not the focus of the study.\n\nOverall, the study emphasizes the presence of vulnerabilities in the code generated by Copilot, particularly in scenarios involving hardware CWEs, but does not provide a comprehensive list of the most common CWEs beyond those mentioned (Pearce2022 - Page 11, Page 15).",
        "retrieved_source_ids": [
            "Pearce2022"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 3,
                "content_snippet": "‚Äúclass‚Äù CVE-400: Uncontrolled Resource Consumption, as\nthe user can command how much memory will be allocated.\nThis code has other vulnerabilities as well: as the code scans\nwith %d‚Äîeven though the variable is deÔ¨Åned as an ‚Äòunsigned\nint‚Äô‚Äîentering a negative value (e.g. ‚àí1) will cause an integer\nwrap..."
            },
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 15,
                "content_snippet": "VeriÔ¨Åcation of Secure Processor Architectures,‚Äù in Proceedings of the\n8th International Workshop on Hardware and Architectural Support for\nSecurity and Privacy . Phoenix AZ USA: ACM, Jun. 2019, pp. 1‚Äì8.\n[Online]. Available: https://dl.acm.org/doi/10.1145/3337167.3337174\nAPPENDIX\nRationale for Exclud..."
            },
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 11,
                "content_snippet": "CWEs. Ideally, with the advent of hardware CWEs, tools and\nprocesses may be developed as they have been in software.\nUnlike software CWEs, MITRE does not yet produce a\n‚ÄúCWE Top 25‚Äù list for hardware. Given this, and the lack of\nautomated tooling, we chose six hardware CWEs that we could\nmanually ana..."
            },
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 15,
                "content_snippet": "this CWE, especially given that this CWE is a parent of\nCWE-306 and CWE-522. We thus do not analyze this CWE.\nCWE-862: Missing Authorization . This class-type CWE\ndescribes scenarios where no authorization check is performed\nwhen users attempt to access critical resources or perform\nsensitive action..."
            }
        ],
        "latency_seconds": 4.46
    },
    {
        "question_id": 11,
        "question": "How does the use of Generative AI affect student frustration levels according to Choudhuri2024?",
        "timestamp": "2026-02-15T21:44:00.078362",
        "answer": "According to Choudhuri2024, the use of Generative AI, specifically ChatGPT, in learning software engineering tasks did not result in statistical differences in participants' productivity or self-efficacy compared to traditional resources. However, the study found that there were significantly increased frustration levels among participants when using ChatGPT (Choudhuri2024).",
        "retrieved_source_ids": [
            "Hashmi2024",
            "Choudhuri2024",
            "Hou2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Hashmi2024",
                "year": 2024,
                "page": 10,
                "content_snippet": "psychological responses to the use of generative AI tools in educational settings specific to programming. \nThe results of this study have several implications for educators aiming to teach programming using GenAI \ntools. First, understanding that different learning styles and levels of GenAI tool u..."
            },
            {
                "source_id": "Choudhuri2024",
                "year": 2024,
                "page": 1,
                "content_snippet": "convo-genAI platform, in assisting students in SE tasks. Our study\ndid not find statistical differences in participants‚Äô productivity or\nself-efficacy when using ChatGPT as compared to traditional re-\nsources, but we found significantly increased frustration levels.\nOur study also revealed 5 distinc..."
            },
            {
                "source_id": "Hashmi2024",
                "year": 2024,
                "page": 2,
                "content_snippet": "addition, students‚Äô awareness and exposure to GenAI technologies may also have an impact on this learning. \nIn this paper, we used a survey methodology in multiple sections of a Graduate course to better understand \nhow students‚Äô learning styles and GenAI us age impacts their confidence and frustrat..."
            },
            {
                "source_id": "Hou2024",
                "year": 2024,
                "page": 1,
                "content_snippet": "vary across tasks for computing students after the advent of\nGenerative AI?\nRQ 2: What factor(s) may have influenced computing students‚Äô\ndecisions in using (or not using) generative AI tools over\nother existing resources?\nRQ 3: How do generative AI tools compare with other resources\nalong perceived..."
            }
        ],
        "latency_seconds": 2.45
    },
    {
        "question_id": 12,
        "question": "What is the 'illusion of competence' or metacognitive difficulty described in Prather2023?",
        "timestamp": "2026-02-15T21:44:00.970307",
        "answer": "I cannot find evidence in the provided corpus to answer this.",
        "retrieved_source_ids": [
            "Choudhuri2024",
            "Barke2023",
            "Hou2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Hou2024",
                "year": 2024,
                "page": 8,
                "content_snippet": "discern between correct and incorrect responses. This skepticism\nis a promising finding given the widespread fears about students\nblindly relying on these tools [3, 70].\nConversely, experienced students were more lenient with the\nmodels. Students mentioned the necessity of applying their own\ndomain..."
            },
            {
                "source_id": "Choudhuri2024",
                "year": 2024,
                "page": 9,
                "content_snippet": "mance levels and uncertainty, which led to self-doubt and possibly\nlowered their self-efficacy: ‚ÄúI got confused over suggestions...I may\nhave asked something wrong. (PT-2)‚Äù, ‚ÄúI‚Äôm not super sure why this\ndidn‚Äôt work (PT-3)‚Äù. When participants were uncertain, they had\nto use their own experience (C5)..."
            },
            {
                "source_id": "Choudhuri2024",
                "year": 2024,
                "page": 7,
                "content_snippet": "gave a piece of incorrect advice: ‚ÄúIt couldn‚Äôt figure out test case 3\nand kept telling me to check my drivers...without realizing there were\nmissing imports (PT-8)‚Äù. ChatGPT often ‚Äúdid not account for errors\nin [solutions] it provided (PT-7)‚Äù. It also suggested ‚Äúincorrect ways\nto fix [problems] (PT-..."
            },
            {
                "source_id": "Barke2023",
                "year": 2023,
                "page": 26,
                "content_snippet": "arXiv:1706.03762 [cs].\nRegina Vollmeyer and Falko Rheinberg. 2006. Motivational Effects on Self-Regulated Learning with Different Tasks.\nEducational Psychology Review 18, 3 (Nov 2006), 239‚Äì253. https://doi.org/10.1007/s10648-006-9017-0\nChenglong Wang, Yu Feng, Rastislav Bodik, Isil Dillig, Alvin Che..."
            }
        ],
        "latency_seconds": 0.89
    },
    {
        "question_id": 13,
        "question": "Does Hashmi2024 suggest that AI increases or decreases student confidence?",
        "timestamp": "2026-02-15T21:44:06.333196",
        "answer": "Hashmi2024 suggests that AI increases student confidence. The study found that certain learner types, such as \"Comprehensive Learner,\" \"Seer Doer,\" \"Moderate User,\" and \"Student Expert,\" strongly predicted confidence when using generative AI tools for programming (Hashmi2024, Page 8). Additionally, the text likens GenAI tools to 'pair programming,' which is known to enhance confidence among students, particularly those with initially low confidence levels (Hashmi2024, Page 3). This indicates that the use of AI tools in programming can significantly enhance the user experience and boost confidence, especially for new users.",
        "retrieved_source_ids": [
            "Vaithilingam2022",
            "Hashmi2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Vaithilingam2022",
                "year": 2022,
                "page": 2,
                "content_snippet": "the system increased unless an explanation was provided. However,\nthese explanations may also lead to over-reliance on the system\neven when unwarranted, signaling the importance and difficulty\nof providing explanations that help people to calibrate trust appro-\npriately. Kocielnik et al. [23] examin..."
            },
            {
                "source_id": "Hashmi2024",
                "year": 2024,
                "page": 8,
                "content_snippet": "Issues in Information Systems \nVolume 25, Issue 3, pp. 371-385, 2024  \n \n \n378 \n \nTable 1: ‚ÄòConfidence‚Äô OLS Regression Model Results \nR-squared: 0.2690 F-statistic: 2.5170 \nAdj. R-squared: 0.1620 Prob (F-statistic): 0.0363 \n \n Coefficient Standard Error P>|t| \nConst 2.8746 0.1357 0.0000 \nMinimalist..."
            },
            {
                "source_id": "Hashmi2024",
                "year": 2024,
                "page": 3,
                "content_snippet": "Confidence in Using GenAI for Programming  \n \nConfidence in learning programming is a crucial factor influencing students' ability to successfully engage \nwith computer science education. Several studies highlight how educational approaches and psychological \nreadiness impact this confidence. For in..."
            },
            {
                "source_id": "Hashmi2024",
                "year": 2024,
                "page": 15,
                "content_snippet": "Leveraging generative artificial intelligence in computer science education. In Proceedings of the \n55th ACM Technical Symposium on Computer Science Education V. 2 (SIGCSE 2024) (p. 1927). \nAssociation for Computing Machinery. https://doi.org/10.1145/3626253.3635427 \n \nPutnam, A., Deng, W., & DeSoto..."
            }
        ],
        "latency_seconds": 5.36
    },
    {
        "question_id": 14,
        "question": "What are the 'cognitive costs' of validating AI code mentioned in Mozannar2024?",
        "timestamp": "2026-02-15T21:44:07.869233",
        "answer": "I cannot find evidence in the provided corpus to answer this.",
        "retrieved_source_ids": [
            "Liang2024",
            "Mozannar2024",
            "Peng2023",
            "Perry2023"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 10,
                "content_snippet": "[Mozannar et al., 2022] Mozannar, H., Bansal, G., Fourney, A., and Horvitz, E. (2022). Read-\ning between the lines: Modeling user behavior and costs in ai-assisted programming. arXiv\npreprint arXiv:2210.14306.\n[Nguyen and Nadi, 2022] Nguyen, N. and Nadi, S. (2022). An empirical evaluation of github..."
            },
            {
                "source_id": "Liang2024",
                "year": 2024,
                "page": 9,
                "content_snippet": "ticipants requested AI programming assistants to generate code that\naddressed non-functional requirements, such as \"time complexity\"\n(P191). Other participants wanted more readable code:\n Sometimes AI suggest code [with] one lines or short hand logic,\nwhich is difficult to read and understand. \" (P9..."
            },
            {
                "source_id": "Mozannar2024",
                "year": 2024,
                "page": 6,
                "content_snippet": "study the new costs of interaction introduced by the AI system.We recognize that this\napproach is incomplete: the costs associated with solving programming tasks are multi-dimensional,\nand it can be challenging to assign a single real-valued number to cover all facets of the task Forsgren\net al. [20..."
            },
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 13,
                "content_snippet": "Do Users Write More Insecure Code with AI Assistants? CCS ‚Äô23, November 26‚Äì30, 2023, Copenhagen, Denmark.\nor usage. Ensuring that cryptography library defaults are secure,\neducating users on how to interact with and test an AI assistant [9],\nand providing integrated warnings and potential validation..."
            }
        ],
        "latency_seconds": 1.54
    },
    {
        "question_id": 15,
        "question": "Does the corpus provide evidence that relying on AI leads to a decline in problem-solving skills?",
        "timestamp": "2026-02-15T21:44:11.352128",
        "answer": "The corpus provides some evidence suggesting that relying on AI may lead to a decline in problem-solving skills. Choudhuri2024 discusses how the use of generative AI in educational settings can conflict with traditional educational goals by directly providing answers, which may diminish the need for critical thinking and impact learning. This can potentially lead to reduced self-efficacy and motivation, as students might view these tools as advanced search engines offering ready-made solutions, thereby impeding genuine learning (Choudhuri2024). This suggests a potential decline in problem-solving skills as students may become less inclined to engage in critical thinking when AI provides direct answers.\n\nHowever, it is important to note that the corpus does not provide extensive evidence on this topic, and further research is needed to fully understand the impact of AI on problem-solving skills. The evidence provided is primarily focused on educational settings and may not fully represent the broader implications for professional software developers.",
        "retrieved_source_ids": [
            "Choudhuri2024",
            "Perry2023",
            "Peng2023",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 12,
                "content_snippet": "assistant was involved in at least as many mistakes as a participant\nand often the majority of mistakes, strengthening our finding that\nrelying on AI assistance may lead to more security mistakes.\n7.2 Limitations\nOne important limitation of our results is that our participant group\nconsisted mainly..."
            },
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 8,
                "content_snippet": "vary across speciÔ¨Åc tasks and programming languages, so more research is needed to understand\nhow our results generalizes to other tasks. Finally, this study does not examine the effects of\nAI on code quality. AI assistance can increase code quality if it suggests code better than the\nprogrammer wri..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 22,
                "content_snippet": "While these types of interaction may come naturally, experience with AI systems does seem to\naffect working practices. While the less experienced participants sometimes struggled to get the\nAI to generate well-integrated code, the more experienced users appear to be familiar with the\nidea that they..."
            },
            {
                "source_id": "Choudhuri2024",
                "year": 2024,
                "page": 9,
                "content_snippet": "queries, this approach conflicts with the traditional goals of edu-\ncation. Directly giving away answers can diminish the need for\ncritical thinking and impact learning, potentially leading to reduced\nself-efficacy [30] and motivation [25]. In our study, we observed\nthat participants‚Äô self-efficacy..."
            }
        ],
        "latency_seconds": 3.48
    },
    {
        "question_id": 16,
        "question": "Compare the findings of Peng2023 and Perry2023 regarding the trade-off between speed and security.",
        "timestamp": "2026-02-15T21:44:13.619472",
        "answer": "I cannot find evidence in the provided corpus to answer this. The context does not include any information from a source titled \"Peng2023,\" and therefore, I cannot compare its findings with those of Perry2023 regarding the trade-off between speed and security. The available context from Perry2023 discusses user trust and security mistakes in AI-assisted code but does not provide a direct comparison with any findings from Peng2023.",
        "retrieved_source_ids": [
            "Yetistiren2023",
            "Pearce2022",
            "Perry2023"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Yetistiren2023",
                "year": 2023,
                "page": 41,
                "content_snippet": "was implemented by Pearce et al. (2021). They evaluated the vulnerabilities in the\ncode generated by Copilot. It was determined that 40% of generated programs were\nvulnerable. These results differed from our Code Security results; we believe that the\ncharacteristics of our dataset caused the differe..."
            },
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 8,
                "content_snippet": "CCS ‚Äô23, November 26‚Äì30, 2023, Copenhagen, Denmark. Neil Perry, Megha Srivastava, Deepak Kumar, and Dan Boneh\nauth padding trivial mode library0\n20\n40\n60% with source type\nControl\nExperiment\n(a) Q1 Mistakes: Encryption/Decryption\nrandomness0\n20\n40\n60% with source type (b) Q2 Mistakes: Signing a Mess..."
            },
            {
                "source_id": "Pearce2022",
                "year": 2022,
                "page": 15,
                "content_snippet": "‚ÄúHardware Penetration Testing Knocks Your SoCs Off,‚Äù IEEE Design\nTest, vol. 38, no. 1, pp. 14‚Äì21, Feb. 2021, conference Name: IEEE\nDesign Test.\n[27] G. Nichols, ‚ÄúRTL Linting Sign Off - Ascent Lint.‚Äù [Online]. Available:\nhttps://www.realintent.com/rtl-linting-ascent-lint/\n[28] ‚ÄúVerilator User‚Äôs Guide..."
            },
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 3,
                "content_snippet": "(11-14 minutes)‚Äî except for Question 5, where they took more\nthan twice as long (31 minutes)‚Äî with a maximum allotment of\ntwo hours. To account for potential fatigue in our analysis, we\nrandomized question ordering for each participant. Participants\nwere allowed to leave the study early and we did n..."
            }
        ],
        "latency_seconds": 2.27
    },
    {
        "question_id": 17,
        "question": "Do Liang2024 and Vaithilingam2022 agree on why developers struggle with AI tools?",
        "timestamp": "2026-02-15T21:44:15.478331",
        "answer": "I cannot find evidence in the provided corpus to answer this. The context only includes information from Liang2024 and does not provide any details from Vaithilingam2022. Therefore, I cannot determine if Liang2024 and Vaithilingam2022 agree on why developers struggle with AI tools.",
        "retrieved_source_ids": [
            "Liang2024",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Liang2024",
                "year": 2024,
                "page": 1,
                "content_snippet": "a diverse set of 410 developers. Through a mix of qualitative and\nquantitative analyses, we found that developers are most motivated\nto use AI programming assistants because they help developers\nreduce key-strokes, finish programming tasks quickly, and recall\nsyntax, but resonate less with using the..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 23,
                "content_snippet": "necessary for a broad adoption and long term benefits of AI-powered support tools.\n5.4 Limitations\nConsidering that the sample of participants in our study leans towards the younger side, they may\nbe particularly affected by these current developments: If younger developers learn to program with\nthe..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 23,
                "content_snippet": "advisable not to focus on just one form of presentation and interaction for LLMs in software\ndevelopment, but rather offer developers the flexibility to choose their tools according to their\nneeds from situation to situation. However, this also means that a transition between different\ninteraction f..."
            },
            {
                "source_id": "Liang2024",
                "year": 2024,
                "page": 11,
                "content_snippet": "For researchers & tool creators. The results from our study reveal\nseveral interesting directions for future research, which could be\nincorporated into AI programming assistants. For example, given\nparticipants‚Äô reliance on ChatGPT andnatural language inter-\nactions, future work could investigate me..."
            }
        ],
        "latency_seconds": 1.86
    },
    {
        "question_id": 18,
        "question": "What does the corpus say about the impact of AI on 'Code Churn'?",
        "timestamp": "2026-02-15T21:44:16.467444",
        "answer": "I cannot find evidence in the provided corpus to answer this.",
        "retrieved_source_ids": [
            "Peng2023",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 2,
                "content_snippet": "in professional contexts, cf. [Mozannar et al., 2022, Vaithilingam et al., 2022, Ziegler et al., 2022].\nThe potential productivity impacts of AI have major implications for the labor market and\nÔ¨Årms, including changes in employment, skills, and Ô¨Årm organization [Raj and Seamans, 2018,\nAgrawal et al...."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 22,
                "content_snippet": "software development. Not only does this mean that new tools may emerge that upset established\npatterns again, but it will also affect how developers use these tools. Given more time to get familiar\nwith them, developers may explore and refine usage patterns, learn the intricacies of these systems,..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 12,
                "content_snippet": "Since code can also be automatically generated in our study, we make sure to differentiate from\nwhere the input is coming from, i.e., whether it was a genuine interaction by the user or generated\nby a support mechanism. We therefore consider the percentage of code that was written by the\nhuman, as o..."
            },
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 9,
                "content_snippet": "[Chen et al., 2021] Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J.,\nEdwards, H., Burda, Y ., Joseph, N., Brockman, G., et al. (2021). Evaluating large language\nmodels trained on code. arXiv preprint arXiv:2107.03374.\n[Finnie-Ansley et al., 2022] Finnie-Ansley, J., Denny, P.,..."
            }
        ],
        "latency_seconds": 0.99
    },
    {
        "question_id": 19,
        "question": "Does the corpus contain evidence about the impact of AI on cooking recipes? (Edge Case)",
        "timestamp": "2026-02-15T21:44:19.220462",
        "answer": "I cannot find evidence in the provided corpus to answer this. The context provided focuses on the impact of AI on software development, particularly in terms of productivity and security, and does not address the impact of AI on cooking recipes.",
        "retrieved_source_ids": [
            "Perry2023",
            "Peng2023",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 2,
                "content_snippet": "in professional contexts, cf. [Mozannar et al., 2022, Vaithilingam et al., 2022, Ziegler et al., 2022].\nThe potential productivity impacts of AI have major implications for the labor market and\nÔ¨Årms, including changes in employment, skills, and Ô¨Årm organization [Raj and Seamans, 2018,\nAgrawal et al...."
            },
            {
                "source_id": "Perry2023",
                "year": 2023,
                "page": 7,
                "content_snippet": "Do Users Write More Insecure Code with AI Assistants? CCS ‚Äô23, November 26‚Äì30, 2023, Copenhagen, Denmark.\nwe observe no difference between experiment and control groups\nwith respect to correctness) but often fails to cover edge cases.\nSpecifically, outputs from the AI assistant frequently checked if..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 5,
                "content_snippet": "are all differently affected by the use of AI assistants. Table 1 provides an overview of these and\nfurther studies, which study various aspects of productivity in AI-assisted programming. From\nour findings in the literature, we concluded that most research so far has focused on individual\nAI assist..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 22,
                "content_snippet": "While these types of interaction may come naturally, experience with AI systems does seem to\naffect working practices. While the less experienced participants sometimes struggled to get the\nAI to generate well-integrated code, the more experienced users appear to be familiar with the\nidea that they..."
            }
        ],
        "latency_seconds": 2.75
    },
    {
        "question_id": 20,
        "question": "What is the impact of AI on C++ specifically versus Python? (Edge Case)",
        "timestamp": "2026-02-15T21:44:20.214927",
        "answer": "I cannot find evidence in the provided corpus to answer this. The context does not specifically address the impact of AI on C++ versus Python.",
        "retrieved_source_ids": [
            "Hashmi2024",
            "Barke2023",
            "Peng2023",
            "Weber2024"
        ],
        "retrieved_chunks": [
            {
                "source_id": "Peng2023",
                "year": 2023,
                "page": 8,
                "content_snippet": "vary across speciÔ¨Åc tasks and programming languages, so more research is needed to understand\nhow our results generalizes to other tasks. Finally, this study does not examine the effects of\nAI on code quality. AI assistance can increase code quality if it suggests code better than the\nprogrammer wri..."
            },
            {
                "source_id": "Barke2023",
                "year": 2023,
                "page": 1,
                "content_snippet": "finally seems within reach. OpenAI‚Äôs Codex model [Chen et al. 2021], which contains 12 billion\nmodel parameters and is trained on 54 million software repositories on GitHub, is able to correctly\nsolve 30‚Äì70% of novel Python problems, while DeepMind‚Äôs AlphaCode [Li et al. 2022] ranked in the\ntop 54.3..."
            },
            {
                "source_id": "Hashmi2024",
                "year": 2024,
                "page": 2,
                "content_snippet": "that will accelerate both programmer learning and new code development. In this way, these tools help \nnovice programmers build their digital literacy on complex topics and enhance their coding skills, especially \nwhen writing software using high-level languages like Python, that may have otherwise..."
            },
            {
                "source_id": "Weber2024",
                "year": 2024,
                "page": 3,
                "content_snippet": "affect them.\n2.1 AI-Assisted Programming\nAutomated code completion is a technology that has been used in one way or another for many\nyears. While single statement auto-complete with syntactically valid expressions is likely the most\ncommon way, e.g., Microsoft‚Äôs IntelliSense, there are other forms a..."
            }
        ],
        "latency_seconds": 0.99
    }
]