2026-02-15 18:10:54,688 - INFO - chromadb.telemetry.product.posthog - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-15 18:10:54,798 - INFO - __main__ - Loaded vector store with 1442 documents
2026-02-15 18:10:54,814 - INFO - __main__ - Initialized LLM: gpt-4o
2026-02-15 18:10:55,576 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:10:55,689 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:10:55,707 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 18:10:55,735 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 18:10:55,844 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/model.safetensors "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:10:55,877 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/model.safetensors "HTTP/1.1 302 Found"
2026-02-15 18:10:55,878 - WARNING - huggingface_hub.utils._http - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-15 18:10:56,242 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/xet-read-token/c5ee24cb16019beea0893ab7796b1df96625c6b8 "HTTP/1.1 200 OK"
2026-02-15 18:11:00,571 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:00,715 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:00,731 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 18:11:00,770 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:00,930 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:01,124 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-15 18:11:01,156 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-15 18:11:01,221 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:01,265 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-15 18:11:01,302 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:01,341 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-15 18:11:01,457 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/vocab.txt "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:01,601 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/vocab.txt "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:01,652 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/vocab.txt "HTTP/1.1 200 OK"
2026-02-15 18:11:01,730 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/vocab.txt "HTTP/1.1 200 OK"
2026-02-15 18:11:01,871 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:01,983 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:02,008 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer.json "HTTP/1.1 200 OK"
2026-02-15 18:11:02,198 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer.json "HTTP/1.1 200 OK"
2026-02-15 18:11:02,363 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/added_tokens.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:02,403 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/added_tokens.json "HTTP/1.1 404 Not Found"
2026-02-15 18:11:02,505 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/special_tokens_map.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:02,617 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/special_tokens_map.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:02,645 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/special_tokens_map.json "HTTP/1.1 200 OK"
2026-02-15 18:11:02,671 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/special_tokens_map.json "HTTP/1.1 200 OK"
2026-02-15 18:11:02,707 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/chat_template.jinja "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:02,743 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/chat_template.jinja "HTTP/1.1 404 Not Found"
2026-02-15 18:11:02,861 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:02,913 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:02,931 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md "HTTP/1.1 200 OK"
2026-02-15 18:11:03,032 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md "HTTP/1.1 200 OK"
2026-02-15 18:11:03,068 - INFO - sentence_transformers.cross_encoder.CrossEncoder - Use pytorch device: mps
2026-02-15 18:11:03,589 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:11:03,633 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-15 18:11:03,634 - INFO - __main__ - Cross-encoder reranker initialized
2026-02-15 18:11:03,635 - INFO - __main__ - RAG Engine initialized successfully
2026-02-15 18:11:11,985 - INFO - __main__ - Processing query: Does using AI assistants improve developer productivity, and are there any security risks?
2026-02-15 18:11:13,176 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:11:13,209 - INFO - __main__ - MMR retrieval: 6 documents for query: Does using AI assistants improve developer product...
2026-02-15 18:11:16,794 - INFO - __main__ - Reranked 6 docs -> top 4 (scores: ['6.977', '4.174', '3.997', '2.352'])
2026-02-15 18:11:24,583 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:11:24,594 - INFO - __main__ - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:11:24,595 - INFO - __main__ - Generated response using 3 sources
2026-02-15 18:22:11,791 - INFO - chromadb.telemetry.product.posthog - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-15 18:22:11,868 - INFO - __main__ - Loaded vector store with 1442 documents
2026-02-15 18:22:11,887 - INFO - __main__ - Initialized LLM: gpt-4o
2026-02-15 18:22:12,081 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,120 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,147 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 18:22:12,283 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,315 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,341 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 18:22:12,387 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,422 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,424 - WARNING - huggingface_hub.utils._http - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-15 18:22:12,446 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-15 18:22:12,488 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,528 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-15 18:22:12,565 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,618 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-15 18:22:12,709 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,751 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:12,767 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md "HTTP/1.1 200 OK"
2026-02-15 18:22:12,783 - INFO - sentence_transformers.cross_encoder.CrossEncoder - Use pytorch device: mps
2026-02-15 18:22:13,759 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:22:13,826 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-15 18:22:13,828 - INFO - __main__ - Cross-encoder reranker initialized
2026-02-15 18:22:13,829 - INFO - __main__ - RAG Engine initialized successfully
2026-02-15 18:22:30,153 - INFO - __main__ - Processing query: Does using AI assistants improve developer productivity, and are there any security risks?
2026-02-15 18:22:30,822 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:22:30,846 - INFO - __main__ - MMR retrieval: 6 documents for query: Does using AI assistants improve developer product...
2026-02-15 18:22:31,156 - INFO - __main__ - Reranked 6 docs -> top 4 (scores: ['6.977', '4.174', '3.997', '2.352'])
2026-02-15 18:22:35,021 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:22:35,037 - INFO - __main__ - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:22:35,037 - INFO - __main__ - Generated response using 3 sources
2026-02-15 18:26:54,437 - INFO - chromadb.telemetry.product.posthog - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-15 18:26:54,548 - INFO - rag_engine - Loaded vector store with 1442 documents
2026-02-15 18:26:54,562 - INFO - rag_engine - Initialized LLM: gpt-4o
2026-02-15 18:26:54,751 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:54,785 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:54,802 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 18:26:54,944 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:54,987 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:55,005 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 18:26:55,047 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:55,090 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:55,106 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-15 18:26:55,159 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:55,201 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-15 18:26:55,240 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:55,278 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-15 18:26:55,367 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:55,403 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:55,428 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md "HTTP/1.1 200 OK"
2026-02-15 18:26:55,446 - INFO - sentence_transformers.cross_encoder.CrossEncoder - Use pytorch device: mps
2026-02-15 18:26:56,057 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 "HTTP/1.1 307 Temporary Redirect"
2026-02-15 18:26:56,100 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-15 18:26:56,101 - INFO - rag_engine - Cross-encoder reranker initialized
2026-02-15 18:26:56,101 - INFO - rag_engine - RAG Engine initialized successfully
2026-02-15 18:26:56,103 - INFO - rag_engine - Processing query: How much faster did the treatment group complete the task in the Peng2023 study?
2026-02-15 18:26:57,477 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:26:57,507 - INFO - rag_engine - MMR retrieval: 6 documents for query: How much faster did the treatment group complete t...
2026-02-15 18:26:58,082 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['4.780', '-0.581', '-4.548', '-6.717'])
2026-02-15 18:27:00,342 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:00,352 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:00,352 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:00,352 - INFO - rag_engine - Processing query: What did Weber2024 find regarding the impact of AI on task completion time?
2026-02-15 18:27:00,544 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:00,555 - INFO - rag_engine - MMR retrieval: 6 documents for query: What did Weber2024 find regarding the impact of AI...
2026-02-15 18:27:00,993 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['4.298', '-0.888', '-1.136', '-1.386'])
2026-02-15 18:27:03,523 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:03,533 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:03,534 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:03,534 - INFO - rag_engine - Processing query: Does GitHub Copilot significantly improve task success rates according to Vaithilingam2022?
2026-02-15 18:27:03,749 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:03,768 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does GitHub Copilot significantly improve task suc...
2026-02-15 18:27:04,043 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['7.249', '6.907', '5.423', '5.171'])
2026-02-15 18:27:05,655 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:05,660 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:05,660 - INFO - rag_engine - Generated response using 3 sources
2026-02-15 18:27:05,661 - INFO - rag_engine - Processing query: What is the 'bimodal' interaction pattern (Acceleration vs Exploration) described in Barke2023?
2026-02-15 18:27:05,954 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:05,973 - INFO - rag_engine - MMR retrieval: 6 documents for query: What is the 'bimodal' interaction pattern (Acceler...
2026-02-15 18:27:06,299 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['1.084', '0.271', '-0.579', '-1.345'])
2026-02-15 18:27:10,527 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:10,534 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:10,535 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:10,535 - INFO - rag_engine - Processing query: According to Liang2024, what are the top reasons developers choose to use AI tools?
2026-02-15 18:27:10,647 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:10,656 - INFO - rag_engine - MMR retrieval: 6 documents for query: According to Liang2024, what are the top reasons d...
2026-02-15 18:27:11,065 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['4.904', '3.543', '2.586', '1.780'])
2026-02-15 18:27:13,859 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:13,864 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:13,864 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:13,864 - INFO - rag_engine - Processing query: What percentage of code generated by Copilot contained vulnerabilities in the Pearce2022 study?
2026-02-15 18:27:14,884 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:14,895 - INFO - rag_engine - MMR retrieval: 6 documents for query: What percentage of code generated by Copilot conta...
2026-02-15 18:27:15,020 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['6.713', '4.096', '2.637', '1.136'])
2026-02-15 18:27:17,140 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:17,149 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:17,149 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:17,149 - INFO - rag_engine - Processing query: Does Perry2023 find that users write more secure or less secure code with AI assistants?
2026-02-15 18:27:17,260 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:17,273 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does Perry2023 find that users write more secure o...
2026-02-15 18:27:17,399 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['7.620', '5.853', '5.447', '5.214'])
2026-02-15 18:27:19,800 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:19,804 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:19,804 - INFO - rag_engine - Generated response using 2 sources
2026-02-15 18:27:19,805 - INFO - rag_engine - Processing query: According to Kabir2024, what percentage of ChatGPT answers contained incorrect information?
2026-02-15 18:27:19,956 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:19,973 - INFO - rag_engine - MMR retrieval: 6 documents for query: According to Kabir2024, what percentage of ChatGPT...
2026-02-15 18:27:20,120 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['6.768', '5.743', '3.288', '1.710'])
2026-02-15 18:27:20,785 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:20,793 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:20,793 - INFO - rag_engine - Generated response using 3 sources
2026-02-15 18:27:20,793 - INFO - rag_engine - Processing query: Did Yetistiren2023 find that AI-generated code is more maintainable than human code?
2026-02-15 18:27:20,902 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:20,918 - INFO - rag_engine - MMR retrieval: 6 documents for query: Did Yetistiren2023 find that AI-generated code is ...
2026-02-15 18:27:21,296 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.077', '-0.370', '-0.392', '-1.777'])
2026-02-15 18:27:23,075 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:23,080 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:23,080 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:23,080 - INFO - rag_engine - Processing query: What specific security vulnerabilities (CWEs) were most common in Pearce2022's analysis?
2026-02-15 18:27:24,395 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:24,413 - INFO - rag_engine - MMR retrieval: 6 documents for query: What specific security vulnerabilities (CWEs) were...
2026-02-15 18:27:24,588 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.295', '-1.158', '-2.289', '-4.418'])
2026-02-15 18:27:29,322 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:29,325 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:29,325 - INFO - rag_engine - Generated response using 3 sources
2026-02-15 18:27:29,325 - INFO - rag_engine - Processing query: How does the use of Generative AI affect student frustration levels according to Choudhuri2024?
2026-02-15 18:27:29,836 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:29,854 - INFO - rag_engine - MMR retrieval: 6 documents for query: How does the use of Generative AI affect student f...
2026-02-15 18:27:29,970 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['5.308', '4.258', '4.038', '0.599'])
2026-02-15 18:27:31,063 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:31,068 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:31,068 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:31,068 - INFO - rag_engine - Processing query: What is the 'illusion of competence' or metacognitive difficulty described in Prather2023?
2026-02-15 18:27:32,191 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:32,216 - INFO - rag_engine - MMR retrieval: 6 documents for query: What is the 'illusion of competence' or metacognit...
2026-02-15 18:27:32,401 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-9.970', '-10.788', '-10.934', '-10.940'])
2026-02-15 18:27:33,214 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:33,219 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:33,219 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:33,219 - INFO - rag_engine - Processing query: Does Hashmi2024 suggest that AI increases or decreases student confidence?
2026-02-15 18:27:33,323 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:33,335 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does Hashmi2024 suggest that AI increases or decre...
2026-02-15 18:27:33,424 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-1.708', '-5.836', '-6.113', '-6.572'])
2026-02-15 18:27:35,812 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:35,824 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:35,824 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:35,824 - INFO - rag_engine - Processing query: What are the 'cognitive costs' of validating AI code mentioned in Mozannar2024?
2026-02-15 18:27:36,001 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:36,016 - INFO - rag_engine - MMR retrieval: 6 documents for query: What are the 'cognitive costs' of validating AI co...
2026-02-15 18:27:36,134 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.399', '-6.543', '-6.615', '-8.690'])
2026-02-15 18:27:37,550 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:37,557 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:37,557 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:37,557 - INFO - rag_engine - Processing query: Does the corpus provide evidence that relying on AI leads to a decline in problem-solving skills?
2026-02-15 18:27:37,778 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:37,788 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does the corpus provide evidence that relying on A...
2026-02-15 18:27:37,893 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-3.132', '-5.218', '-5.705', '-6.176'])
2026-02-15 18:27:41,867 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:41,876 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:41,876 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:41,876 - INFO - rag_engine - Processing query: Compare the findings of Peng2023 and Perry2023 regarding the trade-off between speed and security.
2026-02-15 18:27:42,636 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:42,653 - INFO - rag_engine - MMR retrieval: 6 documents for query: Compare the findings of Peng2023 and Perry2023 reg...
2026-02-15 18:27:42,797 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-8.059', '-8.984', '-10.328', '-10.452'])
2026-02-15 18:27:43,762 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:43,768 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:43,768 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:43,768 - INFO - rag_engine - Processing query: Do Liang2024 and Vaithilingam2022 agree on why developers struggle with AI tools?
2026-02-15 18:27:43,942 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:43,957 - INFO - rag_engine - MMR retrieval: 6 documents for query: Do Liang2024 and Vaithilingam2022 agree on why dev...
2026-02-15 18:27:44,097 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['1.388', '-0.147', '-2.375', '-3.259'])
2026-02-15 18:27:45,069 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:45,077 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:45,077 - INFO - rag_engine - Generated response using 3 sources
2026-02-15 18:27:45,078 - INFO - rag_engine - Processing query: What does the corpus say about the impact of AI on 'Code Churn'?
2026-02-15 18:27:45,230 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:45,246 - INFO - rag_engine - MMR retrieval: 6 documents for query: What does the corpus say about the impact of AI on...
2026-02-15 18:27:45,573 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-0.314', '-5.327', '-6.241', '-6.477'])
2026-02-15 18:27:46,116 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:46,122 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:46,122 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:46,123 - INFO - rag_engine - Processing query: Does the corpus contain evidence about the impact of AI on cooking recipes? (Edge Case)
2026-02-15 18:27:46,243 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:46,257 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does the corpus contain evidence about the impact ...
2026-02-15 18:27:46,367 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-4.989', '-5.733', '-8.659', '-9.081'])
2026-02-15 18:27:47,188 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:47,193 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:47,193 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 18:27:47,193 - INFO - rag_engine - Processing query: What is the impact of AI on C++ specifically versus Python? (Edge Case)
2026-02-15 18:27:47,386 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 18:27:47,399 - INFO - rag_engine - MMR retrieval: 6 documents for query: What is the impact of AI on C++ specifically versu...
2026-02-15 18:27:47,525 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.220', '-4.270', '-6.445', '-6.576'])
2026-02-15 18:27:48,221 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 18:27:48,229 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 18:27:48,229 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:23,643 - INFO - chromadb.telemetry.product.posthog - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-15 21:43:23,771 - INFO - rag_engine - Loaded vector store with 1442 documents
2026-02-15 21:43:23,784 - INFO - rag_engine - Initialized LLM: gpt-4o
2026-02-15 21:43:23,893 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:23,932 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:23,949 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 21:43:24,110 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,206 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,229 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 21:43:24,268 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,309 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,332 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-15 21:43:24,375 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,409 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-15 21:43:24,454 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,518 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-15 21:43:24,635 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,729 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:24,747 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md "HTTP/1.1 200 OK"
2026-02-15 21:43:24,776 - INFO - sentence_transformers.cross_encoder.CrossEncoder - Use pytorch device: mps
2026-02-15 21:43:25,400 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 "HTTP/1.1 307 Temporary Redirect"
2026-02-15 21:43:25,437 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-15 21:43:25,438 - INFO - rag_engine - Cross-encoder reranker initialized
2026-02-15 21:43:25,438 - INFO - rag_engine - RAG Engine initialized successfully
2026-02-15 21:43:25,439 - INFO - rag_engine - Processing query: How much faster did the treatment group complete the task in the Peng2023 study?
2026-02-15 21:43:26,596 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:26,624 - INFO - rag_engine - MMR retrieval: 6 documents for query: How much faster did the treatment group complete t...
2026-02-15 21:43:26,918 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['4.780', '-0.581', '-4.548', '-6.717'])
2026-02-15 21:43:28,643 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:28,661 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:28,661 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:28,661 - INFO - rag_engine - Processing query: What did Weber2024 find regarding the impact of AI on task completion time?
2026-02-15 21:43:29,456 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:29,474 - INFO - rag_engine - MMR retrieval: 6 documents for query: What did Weber2024 find regarding the impact of AI...
2026-02-15 21:43:29,581 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['4.298', '-0.888', '-1.136', '-1.386'])
2026-02-15 21:43:32,723 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:32,735 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:32,735 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:32,735 - INFO - rag_engine - Processing query: Does GitHub Copilot significantly improve task success rates according to Vaithilingam2022?
2026-02-15 21:43:33,353 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:33,373 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does GitHub Copilot significantly improve task suc...
2026-02-15 21:43:33,504 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['7.249', '6.907', '5.423', '5.171'])
2026-02-15 21:43:35,434 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:35,441 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:35,441 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:35,441 - INFO - rag_engine - Processing query: What is the 'bimodal' interaction pattern (Acceleration vs Exploration) described in Barke2023?
2026-02-15 21:43:36,173 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:36,191 - INFO - rag_engine - MMR retrieval: 6 documents for query: What is the 'bimodal' interaction pattern (Acceler...
2026-02-15 21:43:36,296 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['1.084', '0.271', '-0.579', '-1.345'])
2026-02-15 21:43:41,031 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:41,036 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:41,037 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:41,037 - INFO - rag_engine - Processing query: According to Liang2024, what are the top reasons developers choose to use AI tools?
2026-02-15 21:43:41,243 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:41,258 - INFO - rag_engine - MMR retrieval: 6 documents for query: According to Liang2024, what are the top reasons d...
2026-02-15 21:43:41,382 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['4.904', '3.543', '2.586', '1.780'])
2026-02-15 21:43:43,956 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:43,964 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:43,964 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:43,965 - INFO - rag_engine - Processing query: What percentage of code generated by Copilot contained vulnerabilities in the Pearce2022 study?
2026-02-15 21:43:44,130 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:44,146 - INFO - rag_engine - MMR retrieval: 6 documents for query: What percentage of code generated by Copilot conta...
2026-02-15 21:43:44,205 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['6.713', '4.096', '2.637', '1.136'])
2026-02-15 21:43:46,778 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:46,787 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:46,787 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:46,787 - INFO - rag_engine - Processing query: Does Perry2023 find that users write more secure or less secure code with AI assistants?
2026-02-15 21:43:46,958 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:46,974 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does Perry2023 find that users write more secure o...
2026-02-15 21:43:47,085 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['7.620', '5.853', '5.447', '5.214'])
2026-02-15 21:43:49,110 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:49,120 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:49,121 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:49,121 - INFO - rag_engine - Processing query: According to Kabir2024, what percentage of ChatGPT answers contained incorrect information?
2026-02-15 21:43:49,924 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:49,940 - INFO - rag_engine - MMR retrieval: 6 documents for query: According to Kabir2024, what percentage of ChatGPT...
2026-02-15 21:43:50,041 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['6.768', '5.743', '3.288', '1.710'])
2026-02-15 21:43:51,494 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:51,505 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:51,505 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:51,505 - INFO - rag_engine - Processing query: Did Yetistiren2023 find that AI-generated code is more maintainable than human code?
2026-02-15 21:43:51,678 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:51,688 - INFO - rag_engine - MMR retrieval: 6 documents for query: Did Yetistiren2023 find that AI-generated code is ...
2026-02-15 21:43:51,795 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.077', '-0.370', '-0.392', '-1.777'])
2026-02-15 21:43:53,163 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:53,173 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:53,173 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:53,174 - INFO - rag_engine - Processing query: What specific security vulnerabilities (CWEs) were most common in Pearce2022's analysis?
2026-02-15 21:43:53,285 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:53,295 - INFO - rag_engine - MMR retrieval: 6 documents for query: What specific security vulnerabilities (CWEs) were...
2026-02-15 21:43:53,446 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.295', '-1.158', '-2.289', '-4.418'])
2026-02-15 21:43:57,622 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:43:57,632 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:43:57,632 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:43:57,633 - INFO - rag_engine - Processing query: How does the use of Generative AI affect student frustration levels according to Choudhuri2024?
2026-02-15 21:43:57,807 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:43:57,825 - INFO - rag_engine - MMR retrieval: 6 documents for query: How does the use of Generative AI affect student f...
2026-02-15 21:43:57,982 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['5.308', '4.258', '4.038', '0.599'])
2026-02-15 21:44:00,064 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:00,077 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:00,078 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:00,078 - INFO - rag_engine - Processing query: What is the 'illusion of competence' or metacognitive difficulty described in Prather2023?
2026-02-15 21:44:00,248 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:00,265 - INFO - rag_engine - MMR retrieval: 6 documents for query: What is the 'illusion of competence' or metacognit...
2026-02-15 21:44:00,412 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-9.970', '-10.788', '-10.934', '-10.940'])
2026-02-15 21:44:00,964 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:00,970 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:00,970 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:00,970 - INFO - rag_engine - Processing query: Does Hashmi2024 suggest that AI increases or decreases student confidence?
2026-02-15 21:44:01,091 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:01,097 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does Hashmi2024 suggest that AI increases or decre...
2026-02-15 21:44:01,186 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-1.708', '-5.836', '-6.113', '-6.572'])
2026-02-15 21:44:06,324 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:06,332 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:06,332 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:06,333 - INFO - rag_engine - Processing query: What are the 'cognitive costs' of validating AI code mentioned in Mozannar2024?
2026-02-15 21:44:06,555 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:06,572 - INFO - rag_engine - MMR retrieval: 6 documents for query: What are the 'cognitive costs' of validating AI co...
2026-02-15 21:44:06,764 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.399', '-6.543', '-6.615', '-8.690'])
2026-02-15 21:44:07,860 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:07,868 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:07,869 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:07,869 - INFO - rag_engine - Processing query: Does the corpus provide evidence that relying on AI leads to a decline in problem-solving skills?
2026-02-15 21:44:08,063 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:08,079 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does the corpus provide evidence that relying on A...
2026-02-15 21:44:08,184 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-3.132', '-5.218', '-5.705', '-6.176'])
2026-02-15 21:44:11,339 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:11,351 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:11,351 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:11,352 - INFO - rag_engine - Processing query: Compare the findings of Peng2023 and Perry2023 regarding the trade-off between speed and security.
2026-02-15 21:44:11,475 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:11,487 - INFO - rag_engine - MMR retrieval: 6 documents for query: Compare the findings of Peng2023 and Perry2023 reg...
2026-02-15 21:44:11,626 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-8.059', '-8.984', '-10.328', '-10.452'])
2026-02-15 21:44:13,607 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:13,618 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:13,619 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:13,619 - INFO - rag_engine - Processing query: Do Liang2024 and Vaithilingam2022 agree on why developers struggle with AI tools?
2026-02-15 21:44:13,817 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:13,832 - INFO - rag_engine - MMR retrieval: 6 documents for query: Do Liang2024 and Vaithilingam2022 agree on why dev...
2026-02-15 21:44:13,949 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['1.388', '-0.147', '-2.375', '-3.259'])
2026-02-15 21:44:15,469 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:15,478 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:15,478 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:15,478 - INFO - rag_engine - Processing query: What does the corpus say about the impact of AI on 'Code Churn'?
2026-02-15 21:44:15,592 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:15,603 - INFO - rag_engine - MMR retrieval: 6 documents for query: What does the corpus say about the impact of AI on...
2026-02-15 21:44:15,909 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-0.314', '-5.327', '-6.241', '-6.477'])
2026-02-15 21:44:16,462 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:16,467 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:16,467 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:16,467 - INFO - rag_engine - Processing query: Does the corpus contain evidence about the impact of AI on cooking recipes? (Edge Case)
2026-02-15 21:44:17,203 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:17,215 - INFO - rag_engine - MMR retrieval: 6 documents for query: Does the corpus contain evidence about the impact ...
2026-02-15 21:44:17,399 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['-4.989', '-5.733', '-8.659', '-9.081'])
2026-02-15 21:44:19,208 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:19,220 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:19,220 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 21:44:19,220 - INFO - rag_engine - Processing query: What is the impact of AI on C++ specifically versus Python? (Edge Case)
2026-02-15 21:44:19,403 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 21:44:19,416 - INFO - rag_engine - MMR retrieval: 6 documents for query: What is the impact of AI on C++ specifically versu...
2026-02-15 21:44:19,536 - INFO - rag_engine - Reranked 6 docs -> top 4 (scores: ['0.220', '-4.270', '-6.445', '-6.576'])
2026-02-15 21:44:20,201 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 21:44:20,214 - INFO - rag_engine - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 21:44:20,214 - INFO - rag_engine - Generated response using 4 sources
2026-02-15 22:20:19,565 - INFO - chromadb.telemetry.product.posthog - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-15 22:20:19,681 - INFO - __main__ - Loaded vector store with 1442 documents
2026-02-15 22:20:19,694 - INFO - __main__ - Initialized LLM: gpt-4o
2026-02-15 22:20:19,873 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:19,918 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:19,918 - WARNING - huggingface_hub.utils._http - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-15 22:20:19,941 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 22:20:20,151 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,193 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,209 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json "HTTP/1.1 200 OK"
2026-02-15 22:20:20,256 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,303 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,329 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-15 22:20:20,398 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,442 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-15 22:20:20,482 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,541 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-15 22:20:20,678 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,725 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:20,747 - INFO - httpx - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md "HTTP/1.1 200 OK"
2026-02-15 22:20:20,781 - INFO - sentence_transformers.cross_encoder.CrossEncoder - Use pytorch device: mps
2026-02-15 22:20:21,478 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 "HTTP/1.1 307 Temporary Redirect"
2026-02-15 22:20:21,537 - INFO - httpx - HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-15 22:20:21,539 - INFO - __main__ - Cross-encoder reranker initialized
2026-02-15 22:20:21,540 - INFO - __main__ - RAG Engine initialized successfully
2026-02-15 22:20:43,876 - INFO - __main__ - Processing query: What are the security risks?
2026-02-15 22:20:44,436 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 22:20:44,460 - INFO - __main__ - MMR retrieval: 6 documents for query: What are the security risks?...
2026-02-15 22:20:44,969 - INFO - __main__ - Reranked 6 docs -> top 4 (scores: ['-7.526', '-8.241', '-8.961', '-9.134'])
2026-02-15 22:20:49,603 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 22:20:49,625 - INFO - __main__ - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 22:20:49,625 - INFO - __main__ - Generated response using 4 sources
2026-02-15 22:24:52,083 - INFO - __main__ - Processing query: What is the impact of AI on C++ specifically versus Python?
2026-02-15 22:24:52,810 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2026-02-15 22:24:52,843 - INFO - __main__ - MMR retrieval: 6 documents for query: What is the impact of AI on C++ specifically versu...
2026-02-15 22:24:53,287 - INFO - __main__ - Reranked 6 docs -> top 4 (scores: ['-2.309', '-3.565', '-3.590', '-5.808'])
2026-02-15 22:24:54,879 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-15 22:24:54,893 - INFO - __main__ - Query logged to /Users/sirutao/Desktop/Spring 2026/AI model Development/AI_Model_RAG/logs/query_log.json
2026-02-15 22:24:54,893 - INFO - __main__ - Generated response using 4 sources
